{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "nlp_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miQaTC5Hxwdx",
        "colab_type": "text"
      },
      "source": [
        "# Post Here: Sub Reddit Suggestion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KvrSytVxwd1",
        "colab_type": "text"
      },
      "source": [
        "Using the top 1000 subreddits and the top 100 posts from each subreddit, we will try to predict and suggest a good subreddit to post to, based upon the text the user inserts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4TzYj_pxwd2",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJC-_47Sxwd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Load list of csv file names\n",
        "csv_list = os.listdir('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v6B1bvJxwd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Put data from csv files into dataframe\n",
        "\n",
        "data = pd.DataFrame()\n",
        "name = []\n",
        "titles = []\n",
        "for x in csv_list:\n",
        "    if x[-3:] == 'csv' and x[:-4]:             # Ensures that file is a csv \n",
        "        df = pd.read_csv('data/{}'.format(x))  # Create a temporary dataframe (df) to load each csv into\n",
        "        for title in df['title'][:100]:        # For each post (limited to 100 in each subreddit) in each csv add a new row\n",
        "            name.append(x[:-4])                # Remove '.csv' from file name and add to list\n",
        "            titles.append(title + x[:-4])      # Add title of post to list + the name of the subreddit to improve accuracy \n",
        "            \n",
        "# Add lists to DataFrame as columns\n",
        "data['name'] = name\n",
        "data['post_title'] = titles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klj9Rvnlxwd9",
        "colab_type": "code",
        "outputId": "e1b8df2d-8d4a-4048-e649-99129b4b7987",
        "colab": {}
      },
      "source": [
        "# Show data\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>post_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1200isplenty</td>\n",
              "      <td>Weighing yourself after a few days of bad eati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1200isplenty</td>\n",
              "      <td>The holiday season truly is magic1200isplenty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1200isplenty</td>\n",
              "      <td>I feel personally attacked right now1200isplenty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1200isplenty</td>\n",
              "      <td>Some Wednesday motivation!1200isplenty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1200isplenty</td>\n",
              "      <td>Oh no my diet plan has been revealed1200isplenty</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           name                                         post_title\n",
              "0  1200isplenty  Weighing yourself after a few days of bad eati...\n",
              "1  1200isplenty      The holiday season truly is magic1200isplenty\n",
              "2  1200isplenty   I feel personally attacked right now1200isplenty\n",
              "3  1200isplenty             Some Wednesday motivation!1200isplenty\n",
              "4  1200isplenty   Oh no my diet plan has been revealed1200isplenty"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXBGn9vOxweB",
        "colab_type": "text"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWsxssO8xweB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data['post_title']\n",
        "y = data['name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrJUoarsxweE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG-eIE2exweG",
        "colab_type": "code",
        "outputId": "1e8bc7c7-4714-45d7-e496-46b29330f953",
        "colab": {}
      },
      "source": [
        "# Show shapes of each set\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((74402,), (24801,), (74402,), (24801,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsGMZE2vxweI",
        "colab_type": "text"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkuxEW_NxweJ",
        "colab_type": "code",
        "outputId": "f162a2b6-ac03-4bff-8fdb-f2fc7688cd51",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# One-Hot Encoding\n",
        "bow_vector = CountVectorizer(stop_words=\"english\", ngram_range=(1,1))\n",
        "\n",
        "# Transforms text to feature vectors that can be used as input \n",
        "tfidf_vector = TfidfVectorizer()\n",
        "\n",
        "# The ML Algorithm used\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Pipeline\n",
        "pipe = Pipeline([('vectorizer', bow_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Train\n",
        "pipe.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Gaming PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "C:\\Users\\Gaming PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='warn', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='warn', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkQuszNUxweM",
        "colab_type": "text"
      },
      "source": [
        "## Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJMhi6BmxweM",
        "colab_type": "code",
        "outputId": "be1c27c9-30e8-41b4-e752-55d6e3f82b96",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Predicting with a test dataset\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "# Model Accuracy\n",
        "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.5635256642877303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMMqZCg5xweP",
        "colab_type": "code",
        "outputId": "24b125dd-486b-4ff4-d249-4b9ac3eb31f7",
        "colab": {}
      },
      "source": [
        "# If the title of the users post includes 'keyboard', it suggests mechanical keyboard! Looks like it is working\n",
        "pipe.predict(['this is my new keyboard!'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['MechanicalKeyboards'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndyqC1yTxweR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model into a plk file : Will save to the same directory as the location of the notebook\n",
        "import pickle\n",
        "\n",
        "model_file_name = 'nlp_model.plk'\n",
        "model_pkl = open(model_file_name, 'wb')\n",
        "pickle.dump(pipe, model_pkl)\n",
        "model_pkl.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}